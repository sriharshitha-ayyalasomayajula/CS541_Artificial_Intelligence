CS541: Artificial Intelligence. 

Image Captioning Using CNN and RNN. 

* Data Source: COCO (Common Objects in Context) image dataset. https://cocodataset.org/#download
* Language: Python (ver 3.10)
* Platform: Jypter Notebook or Python IDLE, Terminal. https://jupyter.org/install
* Software Requirements: Mac OS or Windows 10

Steps:
1. Download the grad_project zip file 
2. Unzip the file. The file contains a folder(code) which consists of four .py files.
3. Run dataset.py from the terminal
4. The data is loaded and preprocessed.
5. Then, run the inference.py from the terminal
6. Also, run preliminaries.py, now the features are extracted, data is preprocessed and is ready to be trained
7. Now, run the training.py from the terminal, the data is split into test and train, a portion of the data is trained and an input image is given and a caption  is generated for the image. 

To Do:
In this project , we created and deployed a visual application to generate a caption for a given image and audio generation. We also test our model against other recent works in image captioning, by making use of CNN and RNN architecture and simplifying the overall design. In the future, we can optimize our model to perform in the real world with high quality audio.




